{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Credit Assignment (up to 30 points to be added to mid-terms)\n",
    "----\n",
    "\n",
    "**Deadline**: 31 March 2016.\n",
    "\n",
    "This is an extra credit assignment. Quesions 1-10 are worth 2 points each. Questison 11 and 12 are worth 12 points each. Points (max 30) will be added to the mid-term exam grade, but the ceiling will still be 100. Hence if you already scored 100 on the mid-terms, this extra credit assignemtn will not be necessary (You are sitll welcome to do it if you wish).\n",
    "\n",
    "**As usual, by submitting this assignment, you agree to abide by the Duke Honor Code that the solutions are your own work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** Find the longest sequence of repated letters (e.g. 'AAA') in the string below. Print 1) the index of the starting location, 2) the actual sequence.\n",
    "\n",
    "```\n",
    "TGTAGTCCATGCGGAATTCCACAGGGGCTCTGGGGACAGATTCGGACCTTTCTGTCAACGCCAATCATGGAGGTAGTGTGAGGTATAAATTTGGTCGGCGTAGGTCAAGAAAACCCACCTGCGCTGCTGTACGACACATGGCCGAGGCTTCAAGGGCATTCCACGAAGAGGCTCATGGCAACGCCTCTCGAAAGCTGGCGCTCAGGAAGGTACGATCACCCTCGAAATCAAAGATTTCATCTGAAATAAAAGTTAGTACGCCACTTTAGGGTATCGAGTACTTACCCATTTATAACGGAGGCTGAGCGAACGCTTGGCTGATGAAAAAACAACACTCGGTATAAACGGCGATTTCCACTGATCCAGGTAAAGCATGTTTGTGGATAGCAAGGGCAAGTAGTATGCAGCGAGTTTCGTGACAGTATAGCTCGACATGTATATCTCTGTGGGCGCATTTGGATGCTGTATACTGTAGAAGCAGTATATTCCCTGATGACCGAACTTACTACAAGTTGTTGTCTCGACAGGTAGTACGTGTGATCTGTGTCTGAGACCTGCAACTGGTGCGCATTGAAACTTCGTACATAAACCTACCGACTTCACCGTTTCGGCGTCGGCTTGTAACTGGAGAGTGTTGTTGCGTCATGGTCGATTGAGGATTTGGCCTAAATGTAGCGCGTATACACTGCATTATTAGCGGCTTCGAGGAACATGTAATGGGCGAGGACAGAGAATTGTATGAGATTCAAACTGCCAGGTTTTATGGCGGACCCCTGCTCCCATTGTAATCGACCGGCGGCTGGGGTACGCCCGCACGAGGGTATCGGTAGTATATCTAGCTAAGCTCCGGTGTATGCTGTTGAGACACCATTCATGCGCAAAGCCCCACCGTGCACGCATGCGATGATAAATAAGGATGACTATGGCTTACAGAGATCTTTTTCAGGGGCGTCTTGCAATAATGGTTGATAAATGTGTTTTGCCGAATCAACTGCGCGGC\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s= '''TGTAGTCCATGCGGAATTCCACAGGGGCTCTGGGGACAGATTCGGACCTTTCTGTCAACGCCAATCATGGAGGTAGTGTGAGGTATAAATTTGGTCGGCGTAGGTCAAGAAAACCCACCTGCGCTGCTGTACGACACATGGCCGAGGCTTCAAGGGCATTCCACGAAGAGGCTCATGGCAACGCCTCTCGAAAGCTGGCGCTCAGGAAGGTACGATCACCCTCGAAATCAAAGATTTCATCTGAAATAAAAGTTAGTACGCCACTTTAGGGTATCGAGTACTTACCCATTTATAACGGAGGCTGAGCGAACGCTTGGCTGATGAAAAAACAACACTCGGTATAAACGGCGATTTCCACTGATCCAGGTAAAGCATGTTTGTGGATAGCAAGGGCAAGTAGTATGCAGCGAGTTTCGTGACAGTATAGCTCGACATGTATATCTCTGTGGGCGCATTTGGATGCTGTATACTGTAGAAGCAGTATATTCCCTGATGACCGAACTTACTACAAGTTGTTGTCTCGACAGGTAGTACGTGTGATCTGTGTCTGAGACCTGCAACTGGTGCGCATTGAAACTTCGTACATAAACCTACCGACTTCACCGTTTCGGCGTCGGCTTGTAACTGGAGAGTGTTGTTGCGTCATGGTCGATTGAGGATTTGGCCTAAATGTAGCGCGTATACACTGCATTATTAGCGGCTTCGAGGAACATGTAATGGGCGAGGACAGAGAATTGTATGAGATTCAAACTGCCAGGTTTTATGGCGGACCCCTGCTCCCATTGTAATCGACCGGCGGCTGGGGTACGCCCGCACGAGGGTATCGGTAGTATATCTAGCTAAGCTCCGGTGTATGCTGTTGAGACACCATTCATGCGCAAAGCCCCACCGTGCACGCATGCGATGATAAATAAGGATGACTATGGCTTACAGAGATCTTTTTCAGGGGCGTCTTGCAATAATGGTTGATAAATGTGTTTTGCCGAATCAACTGCGCGGC'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Write a function that when given $m$ vectors of length $k$ and another $n$ vectos of length $k$, returns an $m \\times n$ matrix of the cosine distance between each pair of vecotrs. Take the cosine distance to be \n",
    "$$\n",
    "\\frac{A \\cdot B}{\\|A\\} \\|B\\|}\n",
    "$$\n",
    "for any two vectors $A$ and $B$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** For the given $x, y$ points given\n",
    "```python\n",
    "x = np.arange(10)\n",
    "y = np.array([  1.58873597,   7.55101533,  10.71372171,   7.90123225,\n",
    "                -2.05877605, -12.40257359, -28.64568712, -46.39822281,\n",
    "                -68.15488905, -97.16032044])\n",
    "```\n",
    "Fnd the errors $\\hat{y_i} - y_i$, where $\\hat{y_i}$ is the least squares estimate for a qadratic polynomial fit at $x_i$. Do this by using `scipy.linalg.solve` and some suitable set of matrices and vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** Find the coordinates of the vector $\\pmatrix{1\\\\ 2 \\\\3}$ with respect to the eigenvectors of the following matrix.\n",
    "```\n",
    "array([[ 0.18673654,  0.20037016,  0.47406091],\n",
    "       [ 0.21715108,  0.44708353,  0.79204575],\n",
    "       [ 0.24299882,  0.51936745,  0.3061621 ]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** Find all solutions to the following system of equations:\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "x+2y-z+w &=& 2\\\\\n",
    "3x-4y+2 w &=& 3\\\\\n",
    "2y+z &=& 4\\\\\n",
    "2x+2y-3z+2w&=&0\\\\\n",
    "-2x+6y-z-w&=&-1\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "Hint: Use some thougth and pencil and paper to find the number of solutions.  Then use Python to find numerical soluions if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**. Let $f(x)$ be a linear transformation of $\\mathbb{R}^3$ such that\n",
    "$$\\begin{eqnarray*}\n",
    "f(e_1) &=& (1,1,3)\\\\\n",
    "f(e_2) &=& (1,0,4)\\\\\n",
    "f(e_3) &=& (0,2,1)\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "* Find a matrix representation for $f$. \n",
    "* Compute the matrix representation for $f$ in the basis$$\\begin{eqnarray*}\n",
    "v_1 &=& (2,3,3)\\\\\n",
    "v_2 &=& (8,5,2)\\\\\n",
    "v_3 &=& (1,0,5)\n",
    "\\end{eqnarray*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** Perform PCA on the following data using an SVD decomposition set and plot the 10 points projected onto the two largest principal compoennts. Only use routines from `numpy` and `scipy.linalg` - that is, do not use `sklearn` or `statsmodels` etc.\n",
    "```python\n",
    "array([[ 0.94355549,  2.7180393 ,  0.89029696,  2.8180393 ],\n",
    "       [ 0.16132502,  0.77487034,  0.02602576,  0.87487034],\n",
    "       [ 0.66260104,  2.14337301,  0.43904014,  2.24337301],\n",
    "       [ 0.57911438,  1.87477094,  0.33537346,  1.97477094],\n",
    "       [ 0.11982661,  0.76629115,  0.01435842,  0.86629115],\n",
    "       [ 0.74043078,  2.57093441,  0.54823774,  2.67093441],\n",
    "       [ 0.91977487,  2.48573684,  0.84598582,  2.58573684],\n",
    "       [ 0.76492319,  2.08640765,  0.58510748,  2.18640765],\n",
    "       [ 0.10102148,  0.55861296,  0.01020534,  0.65861296],\n",
    "       [ 0.88044825,  2.67604717,  0.77518912,  2.77604717]])\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** Implement a Pyhton function to find roots using the bisection method. Use it to find solutions to $x^3 + 4x^2 -3 = x$. Do not use the standard library `bisect` method - the idea is to develop the algorihtm using only basic Python langauge contructs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.** Given the positive definite matrix\n",
    "\n",
    "$$A = \\left(\\begin{matrix} 3 & 4 & 7 & 0\\\\\n",
    "  4 &15 &11 & 3\\\\\n",
    "  7 &11 &21 & 0\\\\\n",
    "  0 & 3 & 0 & 1\\end{matrix}\\right)$$\n",
    "  \n",
    "Construct a basis for $\\mathbb{R}^4$ that is conjugate under $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** Given a positive definite matrix $A$ and some vector $b$, what is the most-efficient way to solve the equation:\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "Explain your answer by comparing the efficiency of your chosen method to the other decomposition methods we have discussed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11**\n",
    "\n",
    "Implement stochastic gradient descent.  In this method, gradient descent is used essentially by fitting *one data point at a time*.  Recall the usual gradient descent step:\n",
    "\n",
    "$$\\beta_{i+1} = \\beta_i - \\nabla \\ell(\\beta_i)$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\nabla \\ell(\\beta_i) = \\sum\\limits_{j=1}^n \\nabla\\ell(\\beta_i,x_j,y_j)$$\n",
    "\n",
    "and $\\ell$ is the log-likelihood function.  All of the data is used to make the next step toward the optimal $\\beta$.  In stochastic gradient descent, only one point at a time is used to determine the next $\\beta$:\n",
    "\n",
    "$$\\beta_{i+1} = \\beta_i - \\alpha\\nabla \\ell(\\beta_i,x_j,y_j)$$\n",
    "\n",
    "where $\\alpha$ is the step size.  For simplicity, we'll take a constant $\\alpha=1$.\n",
    "\n",
    "Implement the following stochastic gradient algorithm:\n",
    " \n",
    "- Shuffle data points (i.e. randomly permute the order of the $(x_j,y_j)$\n",
    "- Refine beta using the iterative formula above over each data point. \n",
    "- Repeat a and b until convergence is reached.\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&action=edit&section=3) gives the following exmaple of how to do least squares minimization: Let's suppose we want to fit a straight line $y = \\! w_1 + w_2 x$ to a training set of two-dimensional points $\\! (x_1, y_1), \\ldots, (x_n, y_n)$ using least squares. The objective function to be minimized is:\n",
    "\n",
    "$$\n",
    "Q(w) = \\sum_{i=1}^n Q_i(w) = \\sum_{i=1}^n \\left(w_1 + w_2 x_i - y_i\\right)^2\n",
    "$$\n",
    "\n",
    "The update step in the sttochastic gradeint descent is:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} :=\n",
    "    \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix}\n",
    "    -  \\eta  \\begin{bmatrix} 2 (w_1 + w_2 x_i - y_i) \\\\ 2 x_i(w_1 + w_2 x_i - y_i) \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Implement stocahstic grdaident descent and see if you can recover the coefficients for the following data set\n",
    "```python\n",
    "np.random.seed(123)\n",
    "x = np.linspace(0, 10, 11)\n",
    "y = 3 + 6*x + np.random.normal(0, 5, 11)\n",
    "```\n",
    "\n",
    "Use $\\alpha = 0.001$ and `max_iter` = 1000. Compare the answers with a model fit using the `statsmodels` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12** Write a Metropolis MCMC routine \"by hand\" to find the parameters of a a robust linear regression using a T distribuiton on the following data set. In other words, replicat the following analyis without using PyMC3 or PyStan.\n",
    "```python\n",
    "niter = 1000\n",
    "with pm.Model() as robust_linreg:\n",
    "    beta = pm.Normal('beta', 0, 10, shape=2)\n",
    "    nu = pm.Exponential('nu', 1/len(x))\n",
    "    sigma = pm.HalfCauchy('sigma', beta=1)\n",
    "\n",
    "    y_est = beta[0] + beta[1]*x\n",
    "    y_obs = pm.StudentT('y_obs', mu=y_est, sd=sigma, nu=nu, observed=y)\n",
    "\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(niter, step)\n",
    "```\n",
    "\n",
    "Use the following dataset\n",
    "```python\n",
    "df = pd.read_csv('xy.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
